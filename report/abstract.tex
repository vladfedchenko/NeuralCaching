
\Large \textbf{Abstract}

\normalsize
Since the inception of computer science, data retrieval speed has been a major bottleneck for numerous applications. The problem has become only worse following the introduction of the Internet with data potentially retrieved from remote locations. To overcome this limitation caching was introduced. The solution is to store the data closer to the location where it is used or store it in a storage device with higher access speed. A large number of caching policies have been proposed but most of them require ad-hoc tuning of different parameters and none emerges as a clear winner across different applications. For this reason, most of the practical caching systems adopt LRU (Least Recently Used) policy because of its simplicity and relatively good performance.

In this report, we explore the possibility of the application of machine learning algorithms to solve the caching problem. We propose a caching policy which utilizes a feedforward neural network and overperforms state of the art policies on both synthetic and real-world request traces. We also examine other approaches using machine learning techniques to handle the problem and compare their performance with our solution.
