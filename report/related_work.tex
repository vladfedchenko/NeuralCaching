\section{Related work}

In early 2018, a number of related articles appeared. In the next section, we will give a quick review of them and justify the uniqueness of our proposed approach.

The first reviewed article is "Competitive caching with machine learned advice" by Thodoris Lykouris and Sergei Vassilvitskii\cite{18}. This article is mostly a theoretical overview of the ability to apply machine learning algorithms for online caching scenarios. During the study, the authors assume the machine learning component to be a "complete black box" with some guarantees on the accuracy. Then the authors expand by providing an algorithm to aid in the classical caching problem with the application of such a machine learning oracle and calculate lower bound of the performance of such algorithm which is later confirmed by some experimental results. The results of the work done by the authors suggest that it is possible to construct a caching policy based on predictions made by a machine learning algorithm and achieve good performance.

Further examination of the topic revealed some attempts of application of learning algorithms trying to improve the performance in multi-node cooperative caching networks\cite{19}, explore the advantages, drawbacks and scalability possibilities of such an approach. While this caching method is also a perspective field, we are going to stick to a classical setting with a single caching node.

Another batch of articles\cite{20, 21} try to propose a solution to handle the caching problem from the other side. While the classical approach is to reactively decide if to cache the object when it is requested, the alternative is to proactively fetch the object if there are reasons to assume that the object is going to be requested in the future. The authors of \cite{20} are trying to estimate the gains of proactive fetching in the context of 5G cellular network base stations, which in part overlaps with multi-node caching. The authors of \cite{21} propose a particular approach for proactive caching which relies on reinforcement learning technique. Reinforcement learning is known to produce unstable results so we will avoid it during our research. Nevertheless, our approach is dealing with classical reactive caching so it can be considered original in relation to this articles.

The final batch of the articles is the closest by nature to our approach. The first of the reviewed articles from this batch is "A Deep Reinforcement Learning-Based Framework for Content Caching"\cite{22}. The authors of the article also utilize deep reinforcement learning framework which, as said before, not always produces stable results. Also, the authors do not test their approach or real-world data. The tests on the synthetic data are also not convincing since the data is generated with a small number of unique objects and a small number of requests. The authors in \cite{23} apply a different model for predictions - recurrent neural networks, deep long short-term memory network in particular. In both \cite{22} and \cite{23}, the authors do not justify why they are using complex prediction models while bypassing more simple model as in our approach. Another issue with the approach proposed in \cite{23} is the usage of one-hot encoding in the cache eviction decision process which does not scale well with a large number of the unique object usually encountered in caching. Anyway, further in the article we will try to reproduce the approach proposed in \cite{23} and compare it with our approach. 

Article \cite{24} is a continuation of work done in \cite{23} with an attempt to extend the application of the policy to multi-node cooperative caching. This may also be a good continuation of development of our approach but it is not explored in this article.

